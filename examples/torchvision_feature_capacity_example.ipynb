{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import models, datasets, transforms\n",
    "\n",
    "import config as config\n",
    "\n",
    "import replica_correlations as rep\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "weights = torch.load(f\"{config.model_path}model_final_checkpoint_phase999.torch\")\n",
    "trunk = weights['classy_state_dict']['base_model']['model']['trunk']\n",
    "trunk = {re.sub('_feature_blocks\\.', '', key) : val for key, val in trunk.items()}\n",
    "dummy_weight = torch.rand((1000, 2048))\n",
    "dummy_bias = torch.rand((1000, ))\n",
    "trunk['fc.weight'] = dummy_weight\n",
    "trunk['fc.bias'] = dummy_bias\n",
    "model = models.resnet50()\n",
    "model.load_state_dict(trunk)\n",
    "model = model.to(device)\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "test_trnsfrm = transforms.Compose([transforms.Resize(256),\n",
    "                                  transforms.CenterCrop(224),\n",
    "                                  transforms.ToTensor(), \n",
    "                                  # transforms.ToDtype(torch.float32, scale=True),\n",
    "                                  transforms.Normalize(mean, std)\n",
    "                                 ])\n",
    "\n",
    "\n",
    "from data_util import getDatasetFromLabel, getPILDatasetFromLabel\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "\n",
    "embeding_dim = 4000\n",
    "kappa = 0    # Specify the margin (usually 0) \n",
    "n_t = 200    # Specify the number of Gaussian vectors to sample (200 or 300 is a good default)\n",
    "\n",
    "c, r, d = [], [], []\n",
    "\n",
    "node_names = ['x', 'avgpool']#['x', 'layer1.0.relu', 'layer1.1.relu_2', 'layer2.0.relu_1', 'layer2.2.relu', 'layer2.3.relu_2', 'layer3.1.relu_1', 'layer3.3.relu', 'layer3.4.relu_2', 'layer4.0.relu_1', 'layer4.1.relu_1', 'layer4.2.relu', 'layer4.2.relu_1', 'layer4.2.relu_2', 'avgpool']\n",
    "category_folder = os.listdir(config.imagenet_path)\n",
    "\n",
    "for node in node_names:\n",
    "    extractor = create_feature_extractor(model, return_nodes=[node])\n",
    "    features = []\n",
    "    for label in category_folder[0:20]:\n",
    "        dataset = getPILDatasetFromLabel(label, top=45, transform=test_trnsfrm)\n",
    "        dataloader = DataLoader(dataset, batch_size=128, shuffle=False)\n",
    "        for batch in dataloader:\n",
    "            with torch.no_grad():\n",
    "                feature = extractor(batch.to(device))\n",
    "                feature = {key: torch.flatten(val.detach(), start_dim=1).cpu().numpy() for key, val in feature.items()}\n",
    "                if not hasattr(extractor, 'random_index'):\n",
    "                    random_index = {}\n",
    "                    for key, val in feature.items():\n",
    "                        print(f\"{key}: {val.shape[1]}\")\n",
    "                        if val.shape[1] > embeding_dim:\n",
    "                            M = np.random.randn(embeding_dim, val.shape[1])\n",
    "                            M /= np.sqrt(np.sum(M*M, axis=1, keepdims=True))\n",
    "                            random_index[key] = M\n",
    "                        else:\n",
    "                            random_index[key] = np.eye(val.shape[1])\n",
    "                    extractor.random_index = random_index\n",
    "                feature = {key: val @ extractor.random_index[key].T for key, val in feature.items()}\n",
    "        features.append(feature)\n",
    "    # alpha, radius, dimension = manifold_analysis([feature[node].T for feature in features], kappa, n_t)  # layer or X?\n",
    "    capacity, *_ = rep.manifold_analysis_corr([feature[node].T for feature in features], kappa, n_t)  # layer or X?\n",
    "    c.append(capacity)\n",
    "    # c.append(1 / np.mean(1 / alpha))\n",
    "    # r.append(np.mean(radius))\n",
    "    # d.append(np.mean(dimension))\n",
    "    del features\n",
    "    del extractor\n",
    "    gc.collect()\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "plt.plot(c, label='Capacity')\n",
    "# fig.savefig('/n/holylabs/LABS/sompolinsky_lab/Everyone/xupan/hierarchy_manifold/figures/c.png')\n",
    "\n",
    "# fig = plt.figure()\n",
    "# plt.plot(r, label='R')\n",
    "# fig.savefig('/n/holylabs/LABS/sompolinsky_lab/Everyone/xupan/hierarchy_manifold/figures/r.png')\n",
    "\n",
    "# fig = plt.figure()\n",
    "# plt.plot(d, label='D')\n",
    "# fig.savefig('/n/holylabs/LABS/sompolinsky_lab/Everyone/xupan/hierarchy_manifold/figures/d.png')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
